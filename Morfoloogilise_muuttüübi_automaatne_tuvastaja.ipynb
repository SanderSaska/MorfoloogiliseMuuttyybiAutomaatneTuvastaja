{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.9\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importimised\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.1.4\n",
      "numpy: 1.26.4\n",
      "sklearn: 1.2.2\n",
      "tensorflow: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"pandas: {pd.__version__}\") # pandas: 2.1.4\n",
    "print(f\"numpy: {np.__version__}\") # numpy: 1.26.4\n",
    "print(f\"sklearn: {sk.__version__}\") # sklearn: 1.2.2\n",
    "print(f\"tensorflow: {tf.__version__}\") # tensorflow: 2.16.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ennustamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selles peatükis on võimalik kasutada mudelit muuttüüpide ennustamiseks sõnadele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgmise koodiga võetakse häälestatud muuttüübi `MultiLabelBinarizer`. Eeldatakse, et fail on kättesaadav kaustas `Binarizers` failinimena `mlb_w.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlb_w(df_algvormidega):\n",
    "  filename = 'Binarizers/mlb_w.pkl'\n",
    "  if os.path.exists(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "      mlb_w = pickle.load(file)\n",
    "  else:\n",
    "    print(\"Ei leidnud olemasolevat sõnaliigi vektoriseerijat MultiLabelBinarizer faili nimega mlb_w.pkl\")\n",
    "    return None\n",
    "  return mlb_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgmise koodiga võetakse häälestatud üldisema sõnaliigi `MultiLabelBinarizer`. Eeldatakse, et fail on kättesaadav kaustas `Binarizers` failinimena `mlb_s.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlb_s_üldisem(df_algvormidega):\n",
    "  pos_to_group = {\n",
    "        \"['A']\": 'n',  # omadussõna - algvõrre (adjektiiv - positiiv), nii käänduvad kui käändumatud, nt kallis või eht, Adjective\n",
    "        \"['C']\": 'n',  # omadussõna - keskvõrre (adjektiiv - komparatiiv), nt laiem, Comparative adjective\n",
    "        \"['D']\": 'u',  # määrsõna (adverb), nt kõrvuti, Adverb\n",
    "        \"['G']\": 'u',  # genitiivatribuut (käändumatu omadussõna), nt balti, Genitive attribute\n",
    "        \"['H']\": 'n',  # pärisnimi, nt Edgar, Proper noun\n",
    "        \"['I']\": 'u',  # hüüdsõna (interjektsioon), nt tere, Interjection\n",
    "        \"['J']\": 'u',  # sidesõna (konjunktsioon), nt ja, Conjunction\n",
    "        \"['K']\": 'u',  # kaassõna (pre/postpositsioon), nt kaudu, Pre/postposition\n",
    "        \"['N']\": 'n',  # põhiarvsõna (kardinaalnumeraal), nt kaks, Cardinal numeral\n",
    "        \"['O']\": 'n',  # järgarvsõna (ordinaalnumeraal), nt teine, Ordinal numeral\n",
    "        \"['P']\": 'n',  # asesõna (pronoomen), nt see, Pronoun\n",
    "        \"['S']\": 'n',  # nimisõna (substantiiv), nt asi, Noun\n",
    "        \"['U']\": 'n',  # omadussõna - ülivõrre (adjektiiv - superlatiiv), nt pikim, Superlative adjective\n",
    "        \"['V']\": 'v',  # tegusõna (verb), nt lugema, Verb\n",
    "        \"['X']\": 'u',  # verbi juurde kuuluv sõna, millel eraldi sõnaliigi tähistus puudub, nt plehku, Adverb-like word used solely with a certain verb\n",
    "        \"['Y']\": 'n',  # lühend, nt USA, Abbreviation or acronym\n",
    "        \"['Z']\": 'u',  # lausemärk, nt -, /, ..., Punctuation\n",
    "        # Siit alates lisaks statistikast leitud read\n",
    "        \"['S', 'S']\": 'n',\n",
    "        \"['A', 'A']\": 'n',\n",
    "        \"['S', 'I']\": 'n',\n",
    "        \"['V', 'V']\": 'v',\n",
    "        \"['D', 'K']\": 'u',\n",
    "        \"['H', 'H']\": 'n',\n",
    "        \"['P', 'P']\": 'n',\n",
    "        \"['S', 'A']\": 'n',\n",
    "        \"['K', 'D']\": 'u',\n",
    "        \"['A', 'S']\": 'n',\n",
    "    }\n",
    "\n",
    "  filename = 'Binarizers/mlb_s.pkl'\n",
    "\n",
    "  if os.path.exists(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "      mlb_s = pickle.load(file)\n",
    "  else:\n",
    "    print(\"Ei leidnud olemasolevat sõnaliigi vektoriseerijat MultiLabelBinarizer faili nimega mlb_s.pkl\")\n",
    "    return None\n",
    "  return mlb_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgmise koodiga võetakse häälestatud sõnade TextVectorization. Eeldatakse, et failid on kättesaadavad kaustas `TextVectorizations` nimedena `text_vectorization_len_20_model_architecture.pkl` ja `text_vectorization_len_20_vocab.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tekst_vect_failid():\n",
    "  # Kaust, kuhu on kogutud kõik TextVectorization'id\n",
    "  kaust = \"./TextVectorizations/\"\n",
    "\n",
    "  vocab_file = kaust + \"text_vectorization_vocab.pkl\" # TextVectorization sõnastik\n",
    "\n",
    "  # Kui on olemas failid, siis loe sisse\n",
    "  if os.path.exists(vocab_file):\n",
    "    with open(vocab_file, \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "\n",
    "    tekst_vect = tf.keras.layers.TextVectorization(split=\"character\",\n",
    "                                                  output_mode=\"int\",\n",
    "                                                  output_sequence_length=20)\n",
    "    tekst_vect.set_vocabulary(vocab)\n",
    "  else:\n",
    "    print(\"Ei leidnud olemasolevat TextVectorization sõnastikku text_vectorization_vocab.pkl\")\n",
    "    return None\n",
    "\n",
    "  return tekst_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgmine funktsioon ehitab üles mudeli, mille sisendiks on ainult sõna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mudel_init():\n",
    "  tf.random.set_seed(7)\n",
    "\n",
    "  # Parameetrid\n",
    "  sõnavara_suurus = 67 # Sõnastiku suurus\n",
    "  output_dim = 49 # Ennustatavate klasside arv\n",
    "  max_pikkus = 20 # Vektori suurus\n",
    "\n",
    "  mudel = tf.keras.models.Sequential()\n",
    "\n",
    "  # Sisend\n",
    "  mudel.add(tf.keras.layers.Input(shape=(max_pikkus, )))\n",
    "\n",
    "  # Embedding\n",
    "  mudel.add(tf.keras.layers.Embedding(input_dim=sõnavara_suurus, output_dim=output_dim, mask_zero=True))\n",
    "\n",
    "  # LSTM\n",
    "  mudel.add(tf.keras.layers.LSTM(160, return_sequences=False))\n",
    "\n",
    "  # Dropout\n",
    "  mudel.add(tf.keras.layers.Dropout(0.0))\n",
    "\n",
    "  # Dense\n",
    "  mudel.add(tf.keras.layers.Dense(output_dim, activation='softmax'))\n",
    "\n",
    "  # Konfigureeri\n",
    "  mudel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  # Treenitud mudeli kaalud\n",
    "  mudel.load_weights(\"./Sonamudel/sonamudel_weights.h5\")\n",
    "\n",
    "  return mudel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgmine funktsioon ehitab üles mudeli, mille sisendiks on sõna ja sõnaliik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mudel_init_sõnaliigiga():\n",
    "  # https://www.tensorflow.org/guide/keras/functional_api#models_with_multiple_inputs_and_outputs\n",
    "  tf.random.set_seed(7)\n",
    "\n",
    "  # Parameetrid\n",
    "  sõnavara_suurus = 67 # Sõnastiku suurus\n",
    "  output_dim_w = 49 # Ennustatavate klasside arv\n",
    "  output_dim_s = 3 # Sõnaliikide klasside arv\n",
    "  max_pikkus = 20 # Vektori suurus\n",
    "\n",
    "  # Sisendid\n",
    "  sõna_input = tf.keras.layers.Input(shape=(max_pikkus,), name='sona')\n",
    "  sõnaliik_input = tf.keras.layers.Input(shape=(output_dim_s,), name='sonaliik')\n",
    "\n",
    "  # Embeddings\n",
    "  sõna_features = tf.keras.layers.Embedding(sõnavara_suurus, output_dim_w)(sõna_input)\n",
    "  sõnaliik_features  = tf.keras.layers.Embedding(output_dim_s, output_dim_w)(sõnaliik_input)\n",
    "\n",
    "  # LSTMs\n",
    "  sõna_features = tf.keras.layers.LSTM(256)(sõna_features)\n",
    "  sõnaliik_features = tf.keras.layers.LSTM(256)(sõnaliik_features)\n",
    "\n",
    "  # Dropout\n",
    "  sõna_features = tf.keras.layers.Dropout(0.2)(sõna_features)\n",
    "  sõnaliik_features = tf.keras.layers.Dropout(0.2)(sõnaliik_features)\n",
    "\n",
    "  # Merge\n",
    "  x = tf.keras.layers.concatenate([sõna_features, sõnaliik_features])\n",
    "\n",
    "  # Dense\n",
    "  muuttüüp_pred = tf.keras.layers.Dense(output_dim_w, activation='softmax')(x)\n",
    "\n",
    "  # Mudeli sisendid ja väljund\n",
    "  mudel = tf.keras.Model(\n",
    "      inputs=[sõna_input, sõnaliik_input],\n",
    "      outputs=[muuttüüp_pred]\n",
    "  )\n",
    "\n",
    "  # Konfigureeri\n",
    "  mudel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  # Treenitud mudeli kaalud\n",
    "  mudel.load_weights(\"./Sonaliigiga_sonamudel/sonaliigiga_sonamudel_weights.h5\")\n",
    "\n",
    "  return mudel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgmine kood on funktsioon muuttüüpide ennustamiseks.\n",
    "\n",
    "Sõnamudeli kasutamiseks eeldatakse sisendiks järjendit sõnadest  kujul `[sõna_1, sõna_2, ...]`.\n",
    "\n",
    "Sõnamudel sõnaliigiga kasutamiseks eeldatakse sisendiks järjendit sõnadest  kujul `[sõna_1, sõna_2, ...]` ja järjendit sõnaliikidest kujul `[sõnaliik_1, sõnaliik_2, ...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leia_muuttüüp(sõna, sõnaliik = ''):\n",
    "\n",
    "  df_algvormidega = pd.read_csv(\"andmed_algvormidega.csv\", header=0, keep_default_na=False)\n",
    "\n",
    "  # Mudeli leidmine\n",
    "  try:\n",
    "    if sõnaliik: # Sõnaliigiga sõnamudel\n",
    "      mudel = mudel_init_sõnaliigiga()\n",
    "    else: # Sõnamudel\n",
    "      mudel = mudel_init()\n",
    "  except OSError as e:\n",
    "    print(f\"{mudeli_path} ei ole mudel\")\n",
    "    return\n",
    "\n",
    "  # TextVectorization\n",
    "  tekst_vect = tekst_vect_failid()\n",
    "  if not tekst_vect:\n",
    "    print(\"Paiguta text_vectorization_vocab.pkl TextVectorizations kausta\")\n",
    "    return\n",
    "  X_w = tekst_vect(sõna)\n",
    "\n",
    "  # Muuttüübid\n",
    "  mlb_w = get_mlb_w(df_algvormidega)\n",
    "  if not mlb_w:\n",
    "    print(\"Paiguta mlb_w.pkl Binarizers kausta\")\n",
    "\n",
    "  # Sõnaliigid\n",
    "  if sõnaliik:\n",
    "    mlb_s = get_mlb_s_üldisem(df_algvormidega)\n",
    "    if not mlb_s:\n",
    "      print(\"Paiguta mlb_s.pkl Binarizers kausta\")\n",
    "      return\n",
    "    sõnaliik = [[s] for s in sõnaliik]\n",
    "    X_s = tf.convert_to_tensor(mlb_s.transform(sõnaliik)) # Ei tohi olla Tensor (sõna) ja mitte Tensor (sõnaliik) koos, sestap convert_to_tensor\n",
    "\n",
    "  # Ennustamine\n",
    "  if sõnaliik:\n",
    "    sisend_tulemused = mudel([X_w, X_s], training=False)\n",
    "  else:\n",
    "    sisend_tulemused = mudel(X_w, training=False)\n",
    "\n",
    "  # Tulemuste salvestamine\n",
    "  tulemused = list()\n",
    "  for tulemus in sisend_tulemused:\n",
    "    indeks = np.argmax(tulemus)\n",
    "    ennustatud_muuttüüp = mlb_w.classes_[indeks]\n",
    "    ennustatud_muuttüüp = re.sub(r\"[\\[\\]']\", \"\", ennustatud_muuttüüp)#.split(',')\n",
    "    # Teisendab muuttüübi andmetüübi täisarvuks\n",
    "    #if len(ennustatud_muuttüüp) > 1:\n",
    "    #  ennustatud_muuttüüp = [int(ennustatud_muuttüüp[0]), int(ennustatud_muuttüüp[1])]\n",
    "    #else:\n",
    "    #  ennustatud_muuttüüp = [int(ennustatud_muuttüüp[0])]\n",
    "    tulemused.append(ennustatud_muuttüüp)\n",
    "\n",
    "  return tulemused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgnev kood kasutab sõnamudelit muuttüübi ennustamiseks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '10', '22', '-', '6', '22', '2']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia_muuttüüp([\"vilistlasel\", \"sinist\", \"musta\", \"ja\", \"valget\", \"ülikoolis\", \"arukalt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgnev kood kasutab sõnamudelit sõnaliigiga muuttüübi ennustamiseks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '10', '22', '-', '1', '22', '-']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia_muuttüüp([\"vilistlasel\", \"sinist\", \"musta\", \"ja\", \"valget\", \"ülikoolis\", \"arukalt\"], ['n', 'n', 'n', 'u', 'n', 'n', 'u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['28, 27', '28', '27', '22', '22', '28, 27']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia_muuttüüp([\"sulgema\", \"sulen\", \"sulgen\", \"sule\", \"sulge\", \"sulgeda\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
